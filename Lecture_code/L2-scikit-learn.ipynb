{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kokchun/Machine-learning-AI22/blob/main/Lecture_code/L2-scikit-learn.ipynb\" target=\"_parent\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; for interacting with the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lecture notes - Scikit-learn intro\n",
    "---\n",
    "\n",
    "This is the lecture note for **scikit-learn**\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that this lecture note gives a brief introduction to scikit-learn. I encourage you to read further about scikit-learn. </p>\n",
    "\n",
    "Read more\n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [train-test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test#sklearn.model_selection.train_test_split)\n",
    "- [scaling data](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html?highlight=mean%20absolute#sklearn.metrics.mean_absolute_error)\n",
    "- [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean%20squared#sklearn.metrics.mean_squared_error)\n",
    "- [OLS](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertisement data\n",
    "\n",
    "We will perform multiple linear regression on the same [advertisement data](https://www.statlearning.com/resources-second-edition) that we worked on in lecture 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 samples\n",
      "3 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "print(f\"{df.shape[0]} samples\")\n",
    "print(f\"{df.shape[1]-1} features\") # subtract one as price_unit_area is the label and not    \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      TV  Radio  Newspaper\n",
       " 1  230.1   37.8       69.2\n",
       " 2   44.5   39.3       45.1,\n",
       " 1    22.1\n",
       " 2    10.4\n",
       " Name: Sales, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(\"Sales\", axis=\"columns\"), df[\"Sales\"]\n",
    "X.head(2), y.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 3), (200,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scikit-learn steps\n",
    "\n",
    "Usually when using Scikit-learn for most algorithms, there are a few steps to follow. However depending on situation, algorithm, dataset, some steps might need to be omitted or additional steps required. \n",
    "\n",
    "Steps: \n",
    "1. train|test split - some cases train|validation|test - split\n",
    "2. Scale the dataset \n",
    "    - many algorithms require scaling, some don't\n",
    "    - which type of scaling to use?\n",
    "    - scale training data, test data to the training data, to avoid data leakage\n",
    "3. Fit the algorithm to the training data\n",
    "4. Transform the training data, transform the test data\n",
    "5. Calculate evaluation metrics\n",
    "\n",
    "Also if when using validation dataset there are some more steps in fine tuning hyperparameters, but we will come back to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 3), (60, 3), (140,), (60,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature scaling\n",
    "\n",
    "Two popular scaling techniques are normalization and feature standardization\n",
    "\n",
    "Normalization (min-max feature scaling)\n",
    "\n",
    "- $X' = \\frac{X-X_{min}}{X_{max}-X_{min}}$\n",
    "\n",
    "Feature standardization (standard score scaling)\n",
    "\n",
    "- $X' = \\frac{X - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 ≤ scaled_X_train ≤ 1.00\n",
      "0.01 ≤ scaled_X_test ≤ 1.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54988164, 0.63709677, 0.52286282],\n",
       "       [0.65843761, 0.96169355, 0.52286282],\n",
       "       [0.98816368, 0.57056452, 0.42644135],\n",
       "       [0.03719986, 0.74395161, 0.44632207],\n",
       "       [0.74264457, 0.98790323, 0.02882704],\n",
       "       [0.25160636, 0.70564516, 0.52087475],\n",
       "       [0.73080825, 0.88508065, 0.26739563],\n",
       "       [0.16672303, 0.23387097, 0.17992048],\n",
       "       [0.74974636, 0.06854839, 0.12723658],\n",
       "       [0.58978695, 0.45362903, 0.31013917],\n",
       "       [0.10415962, 0.49596774, 0.01888668],\n",
       "       [0.18769023, 0.11491935, 0.29224652],\n",
       "       [0.79066622, 0.06854839, 0.83996024],\n",
       "       [0.01589449, 0.60282258, 0.09045726],\n",
       "       [0.46939466, 0.04233871, 0.26143141],\n",
       "       [0.5732161 , 0.15725806, 0.34691849],\n",
       "       [0.02231992, 0.56653226, 0.40854871],\n",
       "       [0.66587758, 0.46975806, 0.13817097],\n",
       "       [0.25228272, 0.40927419, 0.32007952],\n",
       "       [0.80047345, 0.55443548, 0.10636183],\n",
       "       [0.77375719, 0.65120968, 0.73459245],\n",
       "       [0.22691917, 0.73790323, 1.13021869],\n",
       "       [0.12614136, 0.8125    , 0.11530815],\n",
       "       [0.84612783, 0.7358871 , 0.71570577],\n",
       "       [0.23097734, 0.1875    , 0.00596421],\n",
       "       [0.17855935, 0.04032258, 0.20974155],\n",
       "       [0.71964829, 0.86693548, 0.33300199],\n",
       "       [0.4687183 , 0.29233871, 0.09840954],\n",
       "       [0.29252621, 0.23790323, 0.25447316],\n",
       "       [0.02603991, 0.5483871 , 0.01789264],\n",
       "       [0.67331755, 0.05241935, 0.20775348],\n",
       "       [0.2316537 , 0.41330645, 0.17892644],\n",
       "       [0.67027393, 0.99596774, 0.59343936],\n",
       "       [0.05478526, 0.88104839, 0.88568588],\n",
       "       [0.94690565, 0.28024194, 0.36481113],\n",
       "       [0.8031789 , 0.69153226, 0.04970179],\n",
       "       [0.16097396, 0.94758065, 0.08151093],\n",
       "       [0.92323301, 0.58266129, 0.59045726],\n",
       "       [0.39398039, 0.29637097, 0.05069583],\n",
       "       [0.0906324 , 0.03225806, 0.2027833 ],\n",
       "       [0.38992222, 0.15524194, 0.22664016],\n",
       "       [0.59621238, 0.1875    , 0.06063618],\n",
       "       [0.14338857, 0.53830645, 0.34592445],\n",
       "       [0.20831924, 0.25403226, 0.17892644],\n",
       "       [0.75515725, 0.0483871 , 0.15208748],\n",
       "       [0.12681772, 0.07459677, 0.13419483],\n",
       "       [0.23638823, 0.32258065, 0.40258449],\n",
       "       [0.49577274, 0.48185484, 0.18687873],\n",
       "       [0.35136963, 0.11491935, 0.3389662 ],\n",
       "       [0.25566452, 0.55443548, 0.15606362],\n",
       "       [0.26208996, 0.94354839, 0.33996024],\n",
       "       [0.56712885, 0.14314516, 0.12425447],\n",
       "       [0.02705445, 0.9858871 , 0.74254473],\n",
       "       [0.02401082, 0.78427419, 0.5       ],\n",
       "       [0.25600271, 0.01612903, 0.14413519],\n",
       "       [0.43523842, 0.11491935, 0.30815109],\n",
       "       [0.24585729, 0.34274194, 0.12524851],\n",
       "       [0.9773419 , 0.85282258, 0.50596421],\n",
       "       [0.06391613, 0.40524194, 0.16600398],\n",
       "       [0.66587758, 0.07056452, 0.055666  ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use normalization here\n",
    "# instantiate an object from the class MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # use the training data to fit the scaler\n",
    "\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{scaled_X_train.min():.2f} ≤ scaled_X_train ≤ {scaled_X_train.max():.2f}\")\n",
    "print(f\"{scaled_X_test.min():.2f} ≤ scaled_X_test ≤ {scaled_X_test.max():.2f}\") # natural that it isn't [0,1] since we fit to training data \n",
    "\n",
    "# we do not scale our target variable y in this lecture \n",
    "\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Linear regression algorithm\n",
    "\n",
    "### LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [13.02832938  9.88465985  0.69237469]\n",
      "Intercept: 2.7418553248528124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# this model uses SVD approach for solving normal equation\n",
    "model_SVD = LinearRegression()\n",
    "model_SVD.fit(scaled_X_train, y_train)\n",
    "print(f\"Parameters: {model_SVD.coef_}\")\n",
    "print(f\"Intercept: {model_SVD.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [11.94609987  8.9907313   1.35755551]\n",
      "Intercept: [3.58624155]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model_SGD = SGDRegressor(loss = \"squared_error\", learning_rate=\"invscaling\", max_iter = 10000)\n",
    "model_SGD.fit(scaled_X_train, y_train)\n",
    "print(f\"Parameters: {model_SGD.coef_}\")\n",
    "print(f\"Intercept: {model_SGD.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual test\n",
    "\n",
    "We test predict one sample to manually do a reasonability check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features [[0.54988164 0.63709677 0.52286282]], label 16.9\n",
      "Prediction SVD: 16.57\n",
      "Prediction SGD: 16.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.54988164, 0.63709677, 0.52286282])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_features = scaled_X_test[0].reshape(1,-1)\n",
    "test_sample_target = y_test.values[0]\n",
    "\n",
    "print(f\"Scaled features {test_sample_features}, label {test_sample_target}\")\n",
    "print(f\"Prediction SVD: {model_SVD.predict(test_sample_features)[0]:.2f}\")\n",
    "print(f\"Prediction SGD: {model_SGD.predict(test_sample_features)[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation\n",
    "\n",
    "Before we have calculated MAE, MSE, RMSE by ourselves using numpy. Now we will use scikit-learn to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD, MAE: 1.51, MSE: 3.80, RMSE: 1.95\n",
      "SGD, MAE: 1.52, MSE: 4.10, RMSE: 2.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# first predict on our test data \n",
    "y_pred_SVD = model_SVD.predict(scaled_X_test)\n",
    "y_pred_SGD = model_SGD.predict(scaled_X_test)\n",
    "\n",
    "mae_SVD = mean_absolute_error(y_test, y_pred_SVD)\n",
    "mse_SVD = mean_squared_error(y_test, y_pred_SVD)\n",
    "rmse_SVD = np.sqrt(mse_SVD)\n",
    "\n",
    "mae_SGD = mean_absolute_error(y_test, y_pred_SGD)\n",
    "mse_SGD = mean_squared_error(y_test, y_pred_SGD)\n",
    "rmse_SGD = np.sqrt(mse_SGD)\n",
    "\n",
    "print(f\"SVD, MAE: {mae_SVD:.2f}, MSE: {mse_SVD:.2f}, RMSE: {rmse_SVD:.2f}\")\n",
    "print(f\"SGD, MAE: {mae_SGD:.2f}, MSE: {mse_SGD:.2f}, RMSE: {rmse_SGD:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Kokchun Giang\n",
    "\n",
    "[LinkedIn][linkedIn_kokchun]\n",
    "\n",
    "[GitHub portfolio][github_portfolio]\n",
    "\n",
    "[linkedIn_kokchun]: https://www.linkedin.com/in/kokchungiang/\n",
    "[github_portfolio]: https://github.com/kokchun/Portfolio-Kokchun-Giang\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code-CYgrxAwh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d154d3528bab554518fce4b6bb47c23f2c1c42d729e7fb7463b0619040c8c50c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
